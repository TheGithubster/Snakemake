Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	blast
	1

[Sat Oct 20 13:21:55 2018]
Job 0: <-- Starting blast -->

Terminating processes on user request, this might take some time.
[Sat Oct 20 13:21:59 2018]
Error in rule blast:
    jobid: 0
    output: scripts/data/blast_results.out.txt, scripts/data/blast_results.complete-visual-svg.svg

RuleException:
CalledProcessError in line 34 of /home/thomas/Desktop/Snakemake/Snakefile:
Command ' set -euo pipefail;  perl services/ncbiblast_lwp.pl --email "Thom-rein97@hotmail.nl" --sequence copy.fa --database "uniprotkb_bacteria" --stype protein --program blastp --align 7 --alignments 5 --outfile scripts/data/blast_results ' died with <Signals.SIGINT: 2>.
  File "/home/thomas/Desktop/Snakemake/Snakefile", line 34, in __rule_blast
  File "/home/thomas/miniconda3/lib/python3.6/concurrent/futures/thread.py", line 56, in run
Complete log: /home/thomas/Desktop/Snakemake/.snakemake/log/2018-10-20T132155.613718.snakemake.log
